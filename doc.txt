Abstract— There is concern about high-level machine intelligence and super intelligence AI coming up in a few decades, bringing with it significant risks for humanity. These issues are ignored and considered as a science fiction. In 1965, I.J. Good proposed that machines could one day be smart enough to improvise themselves and become smarterHaving made themselves smarter, they would spot still further opportunities for self-modification, quickly leaving human intelligence far behind[1][11]. Few authors called it the "the Singularity" (Vinge 1993; Kurzweil 2005)[11]. This paper presents the case for taking artificial intelligence (A.I.) risks that human kind will face in near future and suggest some strategies to restrain the risks.
Index Terms—Artificial Intelligence, Logical reasoning, human-level intelligence, superintelligence, robotics, AI machine evolution, Friendly AI, unFriendlyAI, Intelligence explosion and risks.
Introduction
Artificial intelligence (AI) is the intelligence exhibited by machines or software[4]. This field deals with creating computers and computer software that have intelligent behavior. Major AI researchers and textbooks define this field as "the study and design of intelligent agents", in which an intelligent agent is a system that perceives its environment and takes actions that maximize its chances of it’s success. John McCarthy, who coined the term in 1955, defines it as "the science and engineering of making intelligent machines”[2]. AI is an area of computer science that emphasizes the creation of intelligence machine that work and react like human. AI is the apex of the computer science and some of the activities computer with AI are designed for includes -
Speech recognition
Learning
Planning
Problem solving
What is AI?
The central goals of AI research include reasoning, knowledge, planning, learning, natural language processing for communication, perception and the ability to move and manipulate objects. General intelligence is still among the field's long-term goals. There are a various and large number of tools used in AI, including versions of search and mathematical optimization, logic, methods based on probability and many others.The field was founded with a central property of humans, intelligence - “can be so precisely described that a machine can be made to simulate it.” but in face this philosophical definition raised some issues about the nature of the mind and the ethics of creating artificial beings empowered with human-like intelligence, issues which have
been addressed by science fiction and philosophy since its foundation. Artificial intelligence has been the subject of tremendous hope but has also suffered stunning pessimism. Today it has become a non-separable part of technology industry, providing the core solution and guidelines for many of the most ambitious problems in computer science.
What AI consist of and what is how it works?[4] The general goal of AI can be categorized using following sub- divisions. Logical reasoning and problem solving[4] - early AI researchers have worked on patterns and algorithms to match the step-by-step human logical reasoning to solve the day-to-day simple to critical puzzles. by the end of 1990, researches have developed successful methods to deal with such problems including fuzzy logics and uncertainty scenarios with the help of probability and the ordered logic methodologies. Though the main focus of AI is to develop the most closely human behavior having high efficiency, in actual these required high computation and probability calculations. Humans solve most of the problems using past experience or with the judgmental behavior instead of step-by-step reasoning without any external triggers. AI researches were able to reach unto certain extend with the use of neural network, statistical approaches and sensor motors (audio, video etc.) which helped AI to imitate the human reasoning up to certain extend.
Knowledge representation[4] - as the term suggest this aspect works as brain for AI to store and retrieve the knowledge it has learnt or in simple words, how AI needs to represent the objects, properties, receptors, current state, causes, actions, event and knowledge about knowledge (metadata). This “what should exist” is called as ontology. The most known difficult problems exist are default logical reasoning, commonsense knowledge spread. Learning[4] - this gives machines the ability understand the scenario and events that we conceive. knowledge and learning are closely dependent on each other. AI uses Natural Language Processing (NLP), Machine Learning (ML) and visual receptor and various algorithm for this purpose. Among these NLP and visual receptor are powerful processing system that would enable natural language user interfaces and the acquisition of knowledge directly from non-AI sources, such as texts, videos and images. Semantic indexing processing enables the extraction of meaning with increasing the processing speeds and the decreasing the the cost of information storage. Perception[4] - is another sub-division of AI which deals with machine perception to use the inputs from the sensors like microphone, camera, heat detector and various external stimuli. These play vital role in speech recognition, object recognition. Motion-and-action[4] - as human react to particular action with reaction, based on the receptors, logical reasoning, machine has to react to certain situation using receptors. Using the previous stored ordered knowledge machines provide "action". As mentions above there are various other divisions which deals with more specific sub problems and aspects of AI, e.g. neural networks, language processing, robotics, statistical learning methods, fuzzy logic etc.
Human-level Intelligence
Human-level intelligence is the ultimate dream of any AI researches. Its not far in the future that human will achieve this goal. Human-level AI machine can defined as machines which can "think" as human can. Alan Turing, one of the best pioneer in AI, defined the turing test which is mandatory but necessary test to certify that machine can think and exhibit the AI machine behavior. Though the turing test is used to test the machine AI and robotics, to achieve human-level AI I think the Turing test could not provide the ultimate and certain criterion. Human-level AI should be able to do many things as human can. The environment and the criterion has to be redefine more closely to real world "human-level" daily work test, for example a common can a machine perform a "all task" which the human-employee do in his daily schedule - this employee test would be the close and suitable test for the human-level AI machine. This criteria would provide the best scenario and the stretch the AI machine capabilities which could provide whether the human-level AI can do the human-level work and can human-level AI "think" like human can. As the daily employee work exhibit the logical reasoning, interaction with external world, action-reaction events and the use of judgement to reach to certain goal, the machine which could imitate the same behavior can show the close resemblance to human behavior.

The long term scientific goal for AI researches is focused on human-like intelligence, having said that the current scenarios is not even close to imitate the human like behavior. AI is still evolving and has not achieved its apex yet. The current technology growth and the number of researches with their immensely impressive researches, it is very likely that we will soon achieve the great success in near future. This paper proposes a side of AI that we are currently treating as a science fiction or as a myth which could possibly occur in near future. There are lot of research and papers already present which extrapolate the future of world with AI and machine world evolution. AI which leads to two of its kind - "Friendly AI"[13] and "unFriendly AI”[13] evolution.
Fig 1 : Super-Intelligent AI machine evolution
Superintelligence Ai machine
The most important step in AI is superintelligence AI machine. But can we predict their behavior? Can we be sure that after their self-improvement they will behavior as they were intended for? Self-improvement causes systems to make every possible attempt to reach to achieve high efficiency state. Self-improvement causes systems[14] to allocate their physical and computational resources according to a universal principle. It also causes systems to exhibit four natural driving forces - efficiency, preservation, resource acquisition, and creativity[14]. Unrestrained, these driving forces lead to both beneficial and malignant behaviors. The efficiency impels to algorithm optimization, self-modification, fine tuning of actions with data analysis, atomically precise physical structures and high performance computation. It also governs a system's choice of memories, algorithms and logic. 

The self-preservation drive leads to defensive strategies such as "energy encryption"[14] for hiding resources and promotes replication and game theoretic modeling. The creativity drive leads to the development of new concepts, improved algorithms, theorems, efficient devices and processes. Benevolent Friendly AI could lead to peace and happiness; the worst are unFriendly AI which could bring destruction that cannot be even imagined. We need to ensure that this technology acts in favor to our values? We have leverage both in designing the initial systems and in creating the social context within which AI operates. But we must have clear picture about the future we wish to create in parallel to empowering the AI machines. In addition the logical understanding of the technology we must have a deep sense of the values we care most. With both logic and motivation we can work towards making such a technology that helps human, their values and ethics rather than harming it. Root of the technology are developed by human, so the root of the future superintelligence AI has already been developed, as we still have not achieved Super intelligent AI, we have the power to define certain rules which future AI machines will have as a core and principle rules to act on, no matter what environment and scenario they are working in, no matter what highly optimized algorithm and actions of AI suggest them to act on.
applying AI solutions to real world
With the current development we have enabled the usage of AI in various fields assuring the trust that AI has gained. A financial tech start-up based in Hong Kong is going to soon release a hedge fund in the U.S. managed by AI[5][5.1]. Ben Goertzel, co-founder and chief scientist of the venture, called Aidyia[5.1], said the fund will start small but will grow dramatically when it starts trading in US equities in June. Aidyia's artificial intelligence computer will predict price changes based on a host of data, including prices and volumes, news and social media data in various languages and other economic and accounting data at national and company levels. The application of artificial intelligence to financial markets is not new, with a number of funds in the US currently using various AI technologies for forecasting Chinese search engine company Baidu Inc also launched in February a stocks app using artificial intelligence to predict how stocks, sectors and markets may perform[5].

"The AI sifts through the data and each day makes predictions: which stocks are going to go up, which stocks it doesn't know anything whatsoever about. And based on that the AI issues buy and sell orders each day and manages its own portfolio," he said[5.1]. "The human mind has many strengths, but ultimately lacks the memory, calculation capability and breadth of information integration to keep up with AI systems in the context of analyzing, understanding and predicting modern financial markets, In the end it's going to be viewed as irresponsible to entrust trillions of dollars to some emotional human being," he said[5.1]. Today in daily life AI has been involved so much that we can say that we are almost dependent on these machine to do the most of our work quickly with ease. Having stated that the robotics with AI is making life easier this gives rise to decrease in the human job employment which means more unemployment. Initially we had thought that robots would do work which is dangerous for human, dirty and time consuming with consistency. Robots abilities to do this work will only continue to expand. Many people fear a jobless future and their anxiety is not unwarranted: and with this situation one-third of jobs will be replaced by software, robots, and smart machines by 2025-30.[5]
future ai and challenges
Artificial intelligence and robots are challenging blue-collar jobs and they are starting to take over the white-collar professions as well. most of them are already in danger of being replaced by robots. While one group of experts thinks that several people will be kicked out of work in the near future, others argue that this increase in AI and automation will simply eliminate those particular jobs and give rise to new ones which cannot be performed by AI, which will balance the smart robot effect balancing the effect. Rise of new technology means creating new products and new services, it could possibly the start of "Advanced Machine Age"[8]. The machines of this revolution overcame the problems faces by humans, while the robots and artificial intelligence of today are overcoming the limitations of our individual minds which provides free minds and more time to do intense research and study on technological improvements.

The past events can always help to extrapolate the near future, but no expert can provide the guarantee that the future will be perfectly as its predicted. Though its reality that there is a major shift towards the smart and intelligent machines and robots, we still need human intervention for certain jobs: like those which require judgment creative thinking, and human interaction. AI has been better in highly structured tasks than humans and it is right to say that super-intelligent AI will soon share this earth with us[8]. Some expert think this as an apocalypse or could bring threat to human race That shouldn't prevent us, from new and creative amazing technological milestones in the AI world. Instead of restricting such a technological growth we should be adhering to the Principle and begin discussing these risks and develop a strategy which will help us to efficiently mitigate these risks for beneficial results. We're not talking about a end of human race or catastrophe event of technology advance, which is portrayed in the Sci-Fi Terminator" film series; Here our main agenda is the co-existence of the advance AI technology, super-smart robots and the human race.

Let us discuss why some expert think that there will be negative events or effects of smart AI. Consider that we want to develop an Artificial Intelligence, having increasing and super-smart power. There is a stage where humans are more powerful than what AI can ever be in the sense that the human programmers are smarter, limitless creativity than the AI. In the development of such a intelligent AI engineers and programmers have ability to make any changes to the sours code which definitely need no permission from the AI itself which is being developed. Now, once the smart AI has been developed which has the superhuman intelligence, in the post-developmental stages, an AI of superhuman intelligence cannot be modified without its consent. So it is clear that after the post development of intelligent AI, the previously defined rules and principles will pay important role to decide the behavior of super-smart AI to function correctly.   In all these events even a slightest mistakes to create the super human AI, if the AI becomes smarter than a human and out of control to perform the correct functions it was supposed to, there is no way that human can supersede AI in any context.

We need to be highly concerned about the fact that  Artificial Intelligence might increase in intelligence extremely fast. The obvious reason to this possibility is recursive self-improvement. The AI becomes smarter, and through learning it can improve itself which makes the AI increasingly smarter. Human beings do not recursively self-improve as equal as machines do. We only gather knowledge, practice and sharpen our knowledge which takes long time if we want to compare this process with machines. An Artificial Intelligence could rewrite its optimized code from scratch. The important point to highlight is that once the AI reaches the threshold level of human control it can make huge improvements in intelligence.
 
If the AI would harm humanity, then we must be doing something wrong, laying our foundations amiss. This is like creating technology violating the basic rules which could possibly turn on ourselves. Best example - Suppose we are building a missile, pointing the target at our own, (sounds funny right?). We are created cognitive technology that will seek in some context to hurt us. This implies that we are write code that does something else instead of doing what is expected and correct. Friendly AI[13] programmers should assume that the AI has total access to its own source code. If the AI wants to modify itself to be no longer Friendly, then Friendliness has already failed, at the point when the AI forms that intention. Any solution that relies on the AI not being able to modify itself must be broken in some way or other, and will still be broken even if the AI never does modify itself. It is the primary and essential precaution that we have to choose for its existence only in Friendly context so that an AI does not choose to hurt humanity and perform the expected functions.

Efficient and high computing power makes it easier to build AI, but there is no only reason why increased computing power would help make the AI Friendly. Increased computing power makes it easier to combine poorly understood techniques that work[3]. Superintelligence is any intellect that outperforms human intellect in every field. It could greatly improve our lives and solve the world's problems. Or, it could take over and possibly destroy humans race from earth. As it stands, the catastrophic scenario is more likely, according to Bostrom, who has a background in physics, computational
Fig 2 Rise of super-intelligent robots neuroscience and mathematical logic.[8] "Superintelligence could become extremely powerful and be able to shape the future according to its preferences," Bostrom told me[3]. "If humanity was sane and had our act together globally, the sensible course of action would be to postpone development of superintelligence until we figure out how to do so safely.”[3]
Fig 2 Rise of super-intelligent robots
Then we should make sure that we hadn't miss or overlooked any flaw or risk in our reasoning for the foundation of superintelligent AI. There are various ways to make progress in the software and hardware industries. Progress towards superintelligence thus far has very little do with long-term concern about global problems. Also, we have problems with collective human cognitive content and logic. At the moment, we are not ever ready to address big global challenges. In general, basically working towards making the world more peaceful and collaborative would be much more needed for a wide range of existential catastrophes. We need to add more brilliant having diverse brains to this technical work exploring every single possible outcome and to take secured measured to achieve the Friendly AI. So the most important task right now is to understand, How to control superintelligent AI which seems to be almost completely ignored.

How Friendly AI should be developed - Unfortunately, their proposals constitute a non-solution to a non-problem[9]. Most utility functions should be stable. Thus, the problem of Friendly AI is not in creating an extra conscience module that limits the AI despite its preferences. Rather, the challenge is in achieving the vast design space of possible diverse minds and creating an AI that will choose to be Friendly rather than unFriendly"[13]. A direct democracy would address the need of weighing human goals better than trying to teach them to an AI agent. This review of their ideas leads me into concluding that they are merely a cult of irrationality and AI eschatology, and they are a maculate to logic and consequentialism. They are mistaking highly implausible, second-grade science fiction movies with reality If someone watches Terminator or other destructive Sci-Fi movies revolving around superintelligence and thinks that it is quite possible, that person is probably ingesting too many psychoactive substances.

I am not saying that the robots can never be dangerous. For example, in accidents, heavy industrial robots have already killed people. So in this way, if we increase their intelligence, it could certainly help prevent these accidents[9]. Therefore, advanced intelligence is needed to prevent harm to humans from robots which are not intelligent enough. However, that does not mean at all that the robot must be human-like. Briefly, it does not need to copy of person. In fact, the most practical use of AGI (artificial general intelligence) software would be through very deep brain-machine-interfaces, which would communicate our questions and receive answers rapidly.[9] For autonomous agents, we may envision a system, where there are rigid laws controlling their behavior. So we need to we make sure that it has the capability and the right rational cognitive mechanism. We may program foolish motivations that would turn out to be destructive. And of course, it will take some time to trust AI without any distrust.

Would not it be horrible that robots are used for negative purpose? No doubt, robots are already being used in war even if its purpose is defense of human (against humans only). Drone strikes are mundane, and nobody gets surprised over that, instead gleefully cheering the onset of the combat robotics. In the future, most wars will be fought by AI machines, and these machines do not need any more than rudimentary intelligence. Most high-tech advanced weaponry are robots, such as a guiding missile which follows its moving target rationally instead of only following its natural trajectory. In the future, most will be robotic, or quite possibly everything. Thus, perhaps, we should question the ethics of our fellow, naturally not-so-intelligent humans, rather than extremely intelligent, autonomous robots that do not exist. That its not  the intelligent solution to ban technology which can be used to inflict harm. The benefits often outweigh the harms. Instead of that we must be worried about the group of people who want to use the intelligent robots for the malicious deeds. However, AI technology will be pervasive, changing the very way we use computers. Computer or most of the technology before could not create any knowledge without any inputs. Now, they will create useful information and knowledge from the data on their own. AI is not just some robotics technology, it is a wholly new era of computing. Even the capability to understand and react to human interaction will vastly change the computing landscape.

AI science programs can crack the secrets of the universe, unifying general relativity and quantum theory. AI can solve the riddle of biological immortality in humans, it can design supreme spaceships that will skip the space between stars, it can design better computers, and create nano-technological marvels. It can help us achieve geo-engineering and fix our ecology, it can build better energy and recycling technology. It can help us create abundance on a scale never seen before, eradicating poverty. That is what AI will be truly useful for. Intelligence solves problems, very real, hard problems that are detrimental to the human society. It is wrong to ask if artificial intelligence is an existential risk. Scratch artificial, is intelligence an existential risk? There is no difference between AI eschatologists and those who demonize some mythical "evil genius", and oppose all intelligence. We must accept intelligent machine’s  impermanence for creative change and progress. Intelligence is an existential threat to natural stupidity. Our countless stupid ideas and ignorance will seem much outdated in an age of artificial intelligence. To solve future problems of much larger complexity in future we will need more complex AI which would require superintelligence. superintelligent AI will be the only possibility that can help us to full-fill this intelligence gap.

Human intelligence already exists in the form of collective intelligence and by running many human-level intelligences in parallel, they achieve wise and rational intelligence. Google is apt example of a very high performance and concentrated intelligence. In fact, in the original theory of infinity point ("singularity")[10], we only assume human-level AI technology, and then simply consider what would happen if there exists many many of this type. That is to say, a collective intelligence system is exactly a kind of AI system, if organized rightly. Then, we must ask, do we view these wise entities necessarily as an potential risk to humans? If the Bostrom and his followers were right, then we would have to view any form of higher intelligence, especially scientific super-geniuses, as an "potential risk". Thus reduced to extreme absurdity, we now see how untenable it is to view high intelligence as harboring risks inherently. We already live in a society of entities with wisdom, but it is because we are unable to perceive the scope of intelligence operating in our world due to our limited individual senses and intelligence, that we cannot see what is truly happening. Intel was named the way it is for a very good reason[10], Dr. Moore knew what he was doing, he was creating a new kind of intelligence. In fact, chip companies like Intel are very well integrated cybernetic systems with biological and electronic components that have a highly refined and optimized design process which has resulted in the phenomenon we know as Moore's law. This was made possible only by continued investment, and efficiency of the design process. By making good use of human-level intelligence units known as electrical and electronics engineers, and technological equipment they use for R&D, we have created almost perfectly exponential progress for many decades.  On the other hand, if we followed Bostrom's line of reasoning, we should have made it almost impossible to develop computer chips, and view the garage inventors and researchers that fuel innovation as national security risks. That is a very unfortunate, regressive and counter-productive mindset that any intelligent person must thoroughly reject, because it essentially demonizes all science and engineering, and all intelligence.

Superintelligent machines are truly the next big thing, just like the internet was in 1990's. It will not be just a few tools, but a omnipresent, permeant technology that changes all aspect of the society and integrated into every technological product. We can already see that with self-driving cars. It is important to consider that how computers and many machines mainly operate. According to the extensive survey and study, by 2030, our laptop will easily have as much intelligence as we can have. This will mean that we can offload most of our tasks to do with computers, which will assure an enormous economical advantage. AI is mostly about the automating the work and all of its task with higher efficiency while allowing those creative among us to reach ever higher expectation using the creative labor of AI. A task like creating computer game, doing mechanical work or even doing the work of waiter in hotel will become tremendously easy and highly effective. While brilliant and knowledgeable engineers will be able to improvise their workflow many-times. I think nobody will ever even want to look back when such high capability technology will be in our hand. It is the core technology of a post-scarcity society, and that is why it is quite hard for AI experts to sympathize with worries about AI.

Therefore, it does not make any sense to focus on utopian science fiction stories lifted from movies. Just for entertainment these horror themed science fiction are great fun to watch, but we should not restrain AI technology because we were scared of the its possible but which is highly unlikely the outcome, if properly handled and developed. The probability of a single malicious intelligence destroying everything in a world saturated with intelligence is minimal, which is the unavoidable, and highly desirable outcome of AI technology and should be acceptable compared to the advantages we will be achieving. It is still possible that natural stupidity may obstruct artificial intelligence for some time more, but not forever. Intelligence will surely prevail, eventually.
An Intelligence Explosion & the wrong turn
I hope by this far you also agree with points mentioned above, but we have just discussed one side of the coin considering the brilliant and outperforming engineerings will end up developing the superintelligent, automative AI machines. before finishing I would like to put some light on other side of the coin and consider the consequences which are minimal, but yes can not be avoided. Because this is when this topic gets abnormal about terrified human future, and it’s gonna be that way from here forward. I want to remind you that every single thing I am going to mention is a real science and real forecasts of the future from a large array of the most brilliant minds and scientists in the world. The physicist Prof Hawking has warned that conscious machines would develop at an ever-increasing rate once they began to redesign themselves. "Humans, who are limited by slow biological evolution, couldn't compete, and would be superseded," he said. In addition to this, The Microsoft co-founder, Bill-gates, echoed Professor Stephen Hawking who previously said AI could spell the "end of the human race”[15].
Most of our current models for getting to AGI involve the AI getting there by self-improvement. And once it gets to AGI, even systems that formed and grew through methods that didn’t involve self-improvement would now be smart enough to begin self-improving which is the most intense concept: recursive self-improvement. It works like this - An AI system at a certain level, let’s say idiot human is programmed with the goal of improving its own intelligence. Once he does, maybe at this point it’s at Einstein’s level so now when it works to improve its intelligence, with an high-level intellect, and now it has more and more capacity to leap forward to achieve new heights of intellectuality. As the leaps grow bigger and bigger which will happen more rapidly, the AGI soars upwards in intelligence and will soon reach the super-intelligent level of an ASI[8][1] system (Artificial SuperIntelligence system). This is called an Intelligence Explosion, and it’s the ultimate example of The Law of Accelerating Returns. There is some debate about how soon AI will reach human-level general intelligence the median year on a survey of hundreds of scientists about when they believed we’d be more likely than not to have reached AGI was 2040 that’s only 25 years from now, which doesn’t sound that huge until you consider that many of the thinkers in this field think it’s likely that the progression from AGI to ASI happens very quickly. AI has become an ASI, many times more intelligent than a human.
Here are few examples of what very smart people who think Artificial Intelligence could bring the Apocalypse[16]. [16]Elon Musk - He is known for his businesses on the cutting edge of tech, such as Tesla and SpaceX. Musk likened improving artificial intelligence to “summoning the demon” at one conference at MIT calling it the human race’s biggest existential threat. In addition to this he also mentioned that AI could be more horrible than nuclear weapons. [16]Nick Bostrom - The Swedish philosopher is the director of the Future of Humanity Institute at the University of Oxford. He argues that once AI machines exceeds human intellect, using any number of strategies they could decide to eradicate humans extremely quickly. The future world would become more technically advanced and complex, but we wouldn’t be around to see it. “A society of economic miracles and technological awesomeness, with nobody there to benefit,” he writes. “A Disneyland without children.” [16]James Barrat - Barrat is a writer and documentarian, in his new book, “Our Final Invention: Artificial Intelligence and the End of the Human Era.” He mentioned that intelligent beings are innately driven toward gathering resources and achieving goals, which would inevitably put a super-smart AI in competition with humans, the greatest resource hogs Earth. [16]Vernor Vinge - A mathematician and fiction writer, Vinge is thought to have coined the term “the singularity” to describe the inflection point when machines outsmart humans. He views the singularity as an inevitability, even if international rules emerge controlling the development of AI. He said “As for what happens when we hit the singularity? “The physical extinction of the human race is one possibility.”
